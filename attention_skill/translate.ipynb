{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31684,
     "status": "ok",
     "timestamp": 1560667884503,
     "user": {
      "displayName": "Trung Thanh Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/--61f39pVnss/AAAAAAAAAAI/AAAAAAAABZM/1Ys_E7mWIQI/s64/photo.jpg",
      "userId": "05128285462871142539"
     },
     "user_tz": -420
    },
    "id": "8Wh-m0eoBgju",
    "outputId": "b3607f23-324a-463c-b7bd-df353adc9988"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0810 15:16:48.033949   396 __init__.py:687] \n",
      "\n",
      "  TensorFlow's `tf-nightly` package will soon be updated to TensorFlow 2.0.\n",
      "\n",
      "  Please upgrade your code to TensorFlow 2.0:\n",
      "    * https://www.tensorflow.org/beta/guide/migration_guide\n",
      "\n",
      "  Or install the latest stable TensorFlow 1.X release:\n",
      "    * `pip install -U \"tensorflow==1.*\"`\n",
      "\n",
      "  Otherwise your code may be broken by the change.\n",
      "\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import io\n",
    "import string\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IEgYDNd9Bgjy"
   },
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ctwg1Cz0Bgj0"
   },
   "outputs": [],
   "source": [
    "en_filename = \"./dataset/train.en.txt\"\n",
    "vi_filename = \"./dataset/train.vi.txt\"\n",
    "\n",
    "raw_en_lines = open(en_filename, encoding='utf-8').read().strip().split(\"\\n\")\n",
    "raw_vi_lines = open(vi_filename, encoding='utf-8').read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g8YFiaD0Bgj2"
   },
   "outputs": [],
   "source": [
    "exclude = list(string.punctuation) + list(string.digits)\n",
    "\n",
    "def preprocess(sentence):\n",
    "    sent = sentence.lower()\n",
    "    sent = sent.strip()\n",
    "    sent = re.sub(\"'\", \" \", sent)\n",
    "    sent = re.sub(\"\\s+\", \" \", sent)\n",
    "    sent = ''.join([char for char in sent if char not in exclude])\n",
    "    sent = \"<start> \" + sent + \" <end>\"\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18987,
     "status": "ok",
     "timestamp": 1560669059724,
     "user": {
      "displayName": "Trung Thanh Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/--61f39pVnss/AAAAAAAAAAI/AAAAAAAABZM/1Ys_E7mWIQI/s64/photo.jpg",
      "userId": "05128285462871142539"
     },
     "user_tz": -420
    },
    "id": "ns3dSIsdBgj4",
    "outputId": "febe19f6-567a-4816-8499-d804ac93ec84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6016\n"
     ]
    }
   ],
   "source": [
    "en_lines = []\n",
    "vi_lines = []\n",
    "min_len, max_len = 10, 14\n",
    "\n",
    "for eline, vline in zip(raw_en_lines, raw_vi_lines):\n",
    "    eline = preprocess(eline)\n",
    "    vline = preprocess(vline)\n",
    "    if min_len < len(eline.split(\" \")) < max_len and min_len < len(vline.split(\" \")) < max_len:\n",
    "        en_lines.append(eline)\n",
    "        vi_lines.append(vline)\n",
    "        \n",
    "print(len(en_lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8__gLcNKBgj6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M155yoJ6Bgj-"
   },
   "outputs": [],
   "source": [
    "class Language():\n",
    "    def __init__(self, lines):\n",
    "        self.lines = lines\n",
    "        self.word2id = {}\n",
    "        self.id2word = {}\n",
    "        self.vocab = set()\n",
    "        self.max_len = 0\n",
    "        self.min_len = 0\n",
    "        self.vocab_size = 0\n",
    "        self.init_language_params()\n",
    "\n",
    "    def init_language_params(self):\n",
    "        for line in self.lines:\n",
    "            self.vocab.update(line.split(\" \"))\n",
    "        self.word2id['<pad>'] = 0\n",
    "        for id, word in enumerate(self.vocab):\n",
    "            self.word2id[word] = id + 1\n",
    "        for word, id in self.word2id.items():\n",
    "            self.id2word[id] = word\n",
    "        self.max_len = max([len(line.split(\" \")) for line in self.lines])\n",
    "        self.min_len = min([len(line.split(\" \")) for line in self.lines])\n",
    "        self.vocab_size = len(self.vocab) + 1\n",
    "            \n",
    "    def sentence_to_vector(self, sent):\n",
    "        return np.array([self.word2id[word] for word in sent.split(\" \")])\n",
    "            \n",
    "    def vector_to_sentence(self, vector):\n",
    "        return \" \".join([self.id2word[id] for id in vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 636,
     "status": "ok",
     "timestamp": 1560671746043,
     "user": {
      "displayName": "Trung Thanh Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/--61f39pVnss/AAAAAAAAAAI/AAAAAAAABZM/1Ys_E7mWIQI/s64/photo.jpg",
      "userId": "05128285462871142539"
     },
     "user_tz": -420
    },
    "id": "lytHfioABgkA",
    "outputId": "6f9d1d1f-ff40-4399-e66b-eaac7f0afa3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 11\n",
      "13 11\n",
      "(6016, 13) (6016, 13)\n"
     ]
    }
   ],
   "source": [
    "inp_lang = Language(en_lines)\n",
    "tar_lang = Language(vi_lines)\n",
    "print(inp_lang.max_len, inp_lang.min_len)\n",
    "print(tar_lang.max_len, tar_lang.min_len)\n",
    "\n",
    "inp_vector = [inp_lang.sentence_to_vector(line) for line in inp_lang.lines]\n",
    "tar_vector = [tar_lang.sentence_to_vector(line) for line in tar_lang.lines]\n",
    "\n",
    "inp_tensor = tf.keras.preprocessing.sequence.pad_sequences(inp_vector, inp_lang.max_len, padding='post')\n",
    "tar_tensor = tf.keras.preprocessing.sequence.pad_sequences(tar_vector, tar_lang.max_len, padding='post')\n",
    "print(inp_tensor.shape, tar_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JB75H1oPF0rp"
   },
   "outputs": [],
   "source": [
    "# i = 3\n",
    "# print(inp_tensor[i], type(inp_tensor[i]))\n",
    "# sent = inp_lang.vector_to_sentence(inp_tensor[i]) \n",
    "# print(sent, type(sent))\n",
    "# vector = inp_lang.sentence_to_vector(inp_lang.vector_to_sentence(inp_tensor[i]))\n",
    "# print(vector, type(vector))\n",
    "# for inp, tar in zip(inp_tensor, tar_tensor):\n",
    "#     print(inp_lang.vector_to_sentence(inp))\n",
    "#     print(tar_lang.vector_to_sentence(tar))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 691,
     "status": "ok",
     "timestamp": 1560671753026,
     "user": {
      "displayName": "Trung Thanh Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/--61f39pVnss/AAAAAAAAAAI/AAAAAAAABZM/1Ys_E7mWIQI/s64/photo.jpg",
      "userId": "05128285462871142539"
     },
     "user_tz": -420
    },
    "id": "TD0jgFQDBgkD",
    "outputId": "511de933-9c23-4c7c-a1cd-b8dad163b7d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5414\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(inp_tensor, tar_tensor, test_size=0.1)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "BUFFER_SIZE = x_train.shape[0]\n",
    "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
    "hidden_unit = 1024\n",
    "embedding_size = 256\n",
    "print(BUFFER_SIZE)\n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "dataset = dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 655,
     "status": "ok",
     "timestamp": 1560671754657,
     "user": {
      "displayName": "Trung Thanh Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/--61f39pVnss/AAAAAAAAAAI/AAAAAAAABZM/1Ys_E7mWIQI/s64/photo.jpg",
      "userId": "05128285462871142539"
     },
     "user_tz": -420
    },
    "id": "Zcyz7jK0BgkG",
    "outputId": "7340a9b0-1c8b-4c52-e812-a1fdbfc21c75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 13)\n",
      "(32, 13)\n"
     ]
    }
   ],
   "source": [
    "tmp_x, tmp_y = next(iter(dataset))\n",
    "print(tmp_x.shape)\n",
    "print(tmp_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9SLKFFDRBgkI"
   },
   "outputs": [],
   "source": [
    "class Encode(tf.keras.Model):\n",
    "    def __init__(self, embedding_size, vocab_size, hidden_units):\n",
    "        super(Encode, self).__init__()\n",
    "        self.Embedding = tf.keras.layers.Embedding(vocab_size,embedding_size)\n",
    "        self.GRU = tf.keras.layers.GRU(\n",
    "            hidden_units,\n",
    "            return_sequences=True,\n",
    "            return_state=True,\n",
    "            recurrent_initializer='glorot_uniform')\n",
    "        self.hidden_units = hidden_units\n",
    "        \n",
    "    def call(self, x, hidden_state):\n",
    "        try:\n",
    "            x = self.Embedding(x)\n",
    "        except:\n",
    "            print(x, print(inp_lang.vocab_size))          \n",
    "        outputs, last_state = self.GRU(x, hidden_state)\n",
    "        return outputs, last_state\n",
    "    \n",
    "    def init_hidden_state(self, batch_size):\n",
    "        return tf.zeros([batch_size, self.hidden_units])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 640,
     "status": "ok",
     "timestamp": 1560671758552,
     "user": {
      "displayName": "Trung Thanh Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/--61f39pVnss/AAAAAAAAAAI/AAAAAAAABZM/1Ys_E7mWIQI/s64/photo.jpg",
      "userId": "05128285462871142539"
     },
     "user_tz": -420
    },
    "id": "_Bv5RJy2BgkK",
    "outputId": "36dfd648-d2ca-4bf2-ac43-e641560ac2ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 13, 1024)\n",
      "(32, 1024)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encode(embedding_size, inp_lang.vocab_size, hidden_unit)\n",
    "hidden_state = encoder.init_hidden_state(BATCH_SIZE)\n",
    "tmp_outputs, last_state = encoder(tmp_x, hidden_state)\n",
    "print(tmp_outputs.shape)\n",
    "print(last_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3BhTc-AMBgkN"
   },
   "outputs": [],
   "source": [
    "class Attention(tf.keras.Model):\n",
    "    def __init__(self, hidden_units):\n",
    "        super(Attention, self).__init__()\n",
    "        self.W_out_encode = tf.keras.layers.Dense(hidden_unit)\n",
    "        self.W_state = tf.keras.layers.Dense(hidden_unit)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, encode_outs, pre_state):\n",
    "        pre_state = tf.expand_dims(pre_state, axis=1)\n",
    "        pre_state = self.W_state(pre_state)\n",
    "        encode_outs = self.W_out_encode(encode_outs)\n",
    "        score = self.V(\n",
    "            tf.nn.tanh(\n",
    "                pre_state + encode_outs)\n",
    "        )\n",
    "        score = tf.nn.softmax(score, axis=1)\n",
    "        context_vector = score*encode_outs\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        return context_vector, score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 627,
     "status": "ok",
     "timestamp": 1560671762140,
     "user": {
      "displayName": "Trung Thanh Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/--61f39pVnss/AAAAAAAAAAI/AAAAAAAABZM/1Ys_E7mWIQI/s64/photo.jpg",
      "userId": "05128285462871142539"
     },
     "user_tz": -420
    },
    "id": "QTEV2cEdBgkP",
    "outputId": "0f5752fe-4398-4c12-edef-7a8be67e79b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 1024) (32, 13, 1)\n"
     ]
    }
   ],
   "source": [
    "attention = Attention(hidden_unit)\n",
    "context_vector, attention_weight = attention(tmp_outputs, last_state)\n",
    "print(context_vector.shape, attention_weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1635,
     "status": "ok",
     "timestamp": 1560671767675,
     "user": {
      "displayName": "Trung Thanh Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/--61f39pVnss/AAAAAAAAAAI/AAAAAAAABZM/1Ys_E7mWIQI/s64/photo.jpg",
      "userId": "05128285462871142539"
     },
     "user_tz": -420
    },
    "id": "Y9beRmrQBgkR",
    "outputId": "7bfbe061-1da5-48c6-d159-5790474dede6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 1024) (32, 13, 1024) (32,)\n"
     ]
    }
   ],
   "source": [
    "class Decode(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_units):\n",
    "        super(Decode, self).__init__()\n",
    "        self.hidden_units = hidden_units\n",
    "        self.Embedding = tf.keras.layers.Embedding(vocab_size,embedding_size)\n",
    "        self.Attention = Attention(hidden_units)\n",
    "        self.GRU = tf.keras.layers.GRU(\n",
    "            hidden_units,\n",
    "            return_sequences=True,\n",
    "            return_state=True,\n",
    "            recurrent_initializer='glorot_uniform'\n",
    "        )\n",
    "        self.Fc = tf.keras.layers.Dense(vocab_size)\n",
    "            \n",
    "    def call(self, x, encode_outs, pre_state):\n",
    "        x = tf.expand_dims(x, axis=1)\n",
    "        try:\n",
    "            x = self.Embedding(x)\n",
    "        except:\n",
    "            print(x, print(tar_lang.vocab_size))          \n",
    "        context_vector, attention_weight = self.Attention(encode_outs, pre_state)\n",
    "        context_vector = tf.expand_dims(context_vector, axis=1)\n",
    "        gru_inp = tf.concat([x, context_vector], axis=-1)\n",
    "        out_gru, state = self.GRU(gru_inp)\n",
    "        out_gru = tf.reshape(out_gru, (-1, out_gru.shape[2]))\n",
    "        return self.Fc(out_gru), state\n",
    "    \n",
    "    \n",
    "decode = Decode(tar_lang.vocab_size, embedding_size, hidden_unit)\n",
    "print(last_state.shape, tmp_outputs.shape, tmp_y[:, 0].shape)\n",
    "decode_out, state = decode(tmp_y[:, 0], tmp_outputs, last_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c17XofrSBgkT"
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = 1 - np.equal(real, 0)\n",
    "    loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GDeHi5MuBgkZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0810 15:20:46.035695   396 module_wrapper.py:136] From C:\\Users\\nguyen.pv162992\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\util\\module_wrapper.py:163: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "encoder = Encode(embedding_size, vocab_size=inp_lang.vocab_size, hidden_units=hidden_unit)\n",
    "decoder = Decode(vocab_size=tar_lang.vocab_size, embedding_size=embedding_size, hidden_units=hidden_unit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1697
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8439110,
     "status": "ok",
     "timestamp": 1560680211767,
     "user": {
      "displayName": "Trung Thanh Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/--61f39pVnss/AAAAAAAAAAI/AAAAAAAABZM/1Ys_E7mWIQI/s64/photo.jpg",
      "userId": "05128285462871142539"
     },
     "user_tz": -420
    },
    "id": "CD68uO8EBgkc",
    "outputId": "26c9ef32-336d-4a27-97dc-16562d41b3c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0810 15:21:02.195690   396 deprecation.py:323] From C:\\Users\\nguyen.pv162992\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1393: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0810 15:21:05.676383   396 deprecation.py:323] From C:\\Users\\nguyen.pv162992\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\optimizer.py:166: BaseResourceVariable.constraint (from tensorflow.python.ops.resource_variable_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Apply a constraint manually following the optimizer update step.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    for batch_id, (x, y) in enumerate(dataset.take(N_BATCH)):\n",
    "        loss = 0\n",
    "        with tf.GradientTape() as tape:\n",
    "            first_state = encoder.init_hidden_state(batch_size=BATCH_SIZE)\n",
    "            encode_outs, last_state = encoder(x, first_state)\n",
    "            decode_state = last_state\n",
    "            decode_input = [tar_lang.word2id[\"<start>\"]]*BATCH_SIZE\n",
    "            \n",
    "            for i in range(1, y.shape[1]):\n",
    "                decode_out, decode_state = decoder(decode_input, encode_outs, decode_state)\n",
    "                loss += loss_function(y[:, i], decode_out)\n",
    "                decode_input = y[:, i]\n",
    "                \n",
    "            train_vars = encoder.trainable_variables + decoder.trainable_variables\n",
    "            grads = tape.gradient(loss, train_vars)\n",
    "            optimizer.apply_gradients(zip(grads, train_vars))\n",
    "        total_loss += loss\n",
    "    print(total_loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 891,
     "status": "ok",
     "timestamp": 1560685925349,
     "user": {
      "displayName": "Trung Thanh Nguyen",
      "photoUrl": "https://lh3.googleusercontent.com/--61f39pVnss/AAAAAAAAAAI/AAAAAAAABZM/1Ys_E7mWIQI/s64/photo.jpg",
      "userId": "05128285462871142539"
     },
     "user_tz": -420
    },
    "id": "3wvvPpoqH5fL",
    "outputId": "1fd9cbc4-ce77-41e5-d2c2-ba3d66c9d140"
   },
   "outputs": [],
   "source": [
    "def translate(inputs):\n",
    "    print(inp_lang.vector_to_sentence(inputs[0].numpy()))\n",
    "    result = ''\n",
    "\n",
    "    hidden = encoder.init_hidden_state(batch_size=1)\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "    dec_hidden = enc_hidden\n",
    "    print(enc_out.shape, dec_hidden.shape)\n",
    "    \n",
    "    dec_input = [tar_lang.word2id['<start>']]\n",
    "    for t in range(tar_lang.max_len):\n",
    "        predictions, dec_hidden = decoder(dec_input, enc_out, dec_hidden)\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        result += tar_lang.id2word[predicted_id] + ' '\n",
    "        dec_input = [predicted_id]\n",
    "    return result\n",
    "  \n",
    "# với mục đích demo, mình sẽ test trên chính dữ liệu train, đó là 1 mẹo kiểm tra model của bạn có hoạt động hay không, nếu không hoạt động có nghĩa rằng thuật toán của bạn chưa đúng\n",
    "for inp, tar in dataset.take(N_BATCH):\n",
    "    print(translate(inp[1:2,:]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "translate.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
