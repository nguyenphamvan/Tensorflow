{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.83218643 0.77541067]\n",
      " [0.76997511 0.46876785]\n",
      " [0.96581968 0.67825979]\n",
      " ...\n",
      " [0.63124273 0.28513545]\n",
      " [0.923342   0.0386201 ]\n",
      " [0.99234342 0.56205141]]\n"
     ]
    }
   ],
   "source": [
    "X_data = np.random.random((10000,2))\n",
    "print(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_weights = np.array([[3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.59820198]\n",
      " [4.18499676]\n",
      " [5.61049823]\n",
      " ...\n",
      " [3.03426999]\n",
      " [2.9245064 ]\n",
      " [5.22523591]]\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "y_data = np.matmul(X_data, sample_weights.transpose())\n",
    "print(y_data)\n",
    "print(y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noise to data\n",
    "y_data = np.add(y_data, np.random.uniform(-0.5,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.51015245],\n",
       "       [4.09694723],\n",
       "       [5.5224487 ],\n",
       "       ...,\n",
       "       [2.94622046],\n",
       "       [2.83645687],\n",
       "       [5.13718638]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data to traning and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 2)\n"
     ]
    }
   ],
   "source": [
    "# X_train shape\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 1)\n"
     ]
    }
   ],
   "source": [
    "# y_train shape\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfe = tf.contrib.eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# khai bao bien\n",
    "\n",
    "W = tfe.Variable([[1.0, 1.0]])\n",
    "b = tfe.Variable(np.random.uniform(-0.2,0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "def linear_regression(inputs):\n",
    "    return tf.matmul(inputs, W, transpose_b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function mean square error\n",
    "def loss_function(model_fn, inputs, labels):\n",
    "    return tf.reduce_mean(tf.square(model_fn(inputs) - labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter\n",
    "learning_rate = 0.002\n",
    "num_steps = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate= learning_rate)\n",
    "\n",
    "# Caculate gradient\n",
    "grad = tfe.implicit_gradients(loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nguyen.pv162992\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py:611: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Step 0 train loss = 6.711505889892578 test lost = 6.851039886474609\n",
      "Step 100 train loss = 4.258688449859619 test lost = 4.349401473999023\n",
      "Step 200 train loss = 2.706514835357666 test lost = 2.7658002376556396\n",
      "Step 300 train loss = 1.7240228652954102 test lost = 1.7630056142807007\n",
      "Step 400 train loss = 1.1018844842910767 test lost = 1.1276962757110596\n",
      "Step 500 train loss = 0.7077040076255798 test lost = 0.7249278426170349\n",
      "Step 600 train loss = 0.45774394273757935 test lost = 0.46933576464653015\n",
      "Step 700 train loss = 0.2990405261516571 test lost = 0.30691394209861755\n",
      "Step 800 train loss = 0.19809143245220184 test lost = 0.2034910023212433\n",
      "Step 900 train loss = 0.1337074339389801 test lost = 0.13744698464870453\n",
      "Step 1000 train loss = 0.09248220175504684 test lost = 0.09509721398353577\n",
      "Step 1100 train loss = 0.06593621522188187 test lost = 0.0677814781665802\n",
      "Step 1200 train loss = 0.04870377108454704 test lost = 0.050016216933727264\n",
      "Step 1300 train loss = 0.03739021345973015 test lost = 0.038329530507326126\n",
      "Step 1400 train loss = 0.029846081510186195 test lost = 0.030520914122462273\n",
      "Step 1500 train loss = 0.024710191413760185 test lost = 0.02519521489739418\n",
      "Step 1600 train loss = 0.021121015772223473 test lost = 0.021468162536621094\n",
      "Step 1700 train loss = 0.018531112000346184 test lost = 0.01877688616514206\n",
      "Step 1800 train loss = 0.01659359037876129 test lost = 0.01676398329436779\n",
      "Step 1900 train loss = 0.015087252482771873 test lost = 0.01520095020532608\n",
      "Step 2000 train loss = 0.013871404342353344 test lost = 0.013942032121121883\n",
      "Step 2100 train loss = 0.012855890206992626 test lost = 0.012893496081233025\n",
      "Step 2200 train loss = 0.011982610449194908 test lost = 0.011994658038020134\n",
      "Step 2300 train loss = 0.01121377944946289 test lost = 0.011205917224287987\n",
      "Step 2400 train loss = 0.01052466593682766 test lost = 0.010501163080334663\n",
      "Step 2500 train loss = 0.009898685850203037 test lost = 0.009862841106951237\n",
      "Step 2600 train loss = 0.009324642829596996 test lost = 0.009278999641537666\n",
      "Step 2700 train loss = 0.008794658817350864 test lost = 0.0087412279099226\n",
      "Step 2800 train loss = 0.008303222246468067 test lost = 0.008243555203080177\n",
      "Step 2900 train loss = 0.007845805026590824 test lost = 0.0077811661176383495\n",
      "Step 3000 train loss = 0.007419121917337179 test lost = 0.0073505244217813015\n",
      "Step 3100 train loss = 0.007020586635917425 test lost = 0.006948838941752911\n",
      "Step 3200 train loss = 0.006647920235991478 test lost = 0.006573681719601154\n",
      "Step 3300 train loss = 0.006299225613474846 test lost = 0.006223038770258427\n",
      "Step 3400 train loss = 0.005972789600491524 test lost = 0.0058951061218976974\n",
      "Step 3500 train loss = 0.005667081102728844 test lost = 0.005588273052126169\n",
      "Step 3600 train loss = 0.005380774382501841 test lost = 0.005301154218614101\n",
      "Step 3700 train loss = 0.00511256093159318 test lost = 0.005032391287386417\n",
      "Step 3800 train loss = 0.004861266352236271 test lost = 0.004780772607773542\n",
      "Step 3900 train loss = 0.004625841975212097 test lost = 0.004545213654637337\n",
      "Step 4000 train loss = 0.004405258223414421 test lost = 0.004324659239500761\n",
      "Step 4100 train loss = 0.004198584705591202 test lost = 0.00411815382540226\n",
      "Step 4200 train loss = 0.004004906862974167 test lost = 0.003924766089767218\n",
      "Step 4300 train loss = 0.003823433769866824 test lost = 0.0037436867132782936\n",
      "Step 4400 train loss = 0.0036533870734274387 test lost = 0.0035741261672228575\n",
      "Step 4500 train loss = 0.0034940459299832582 test lost = 0.0034153463784605265\n",
      "Step 4600 train loss = 0.0033447316382080317 test lost = 0.0032666621264070272\n",
      "Step 4700 train loss = 0.003204829292371869 test lost = 0.003127447562292218\n",
      "Step 4800 train loss = 0.0030737309716641903 test lost = 0.002997088013216853\n",
      "Step 4900 train loss = 0.0029508767183870077 test lost = 0.0028750128112733364\n",
      "Step 5000 train loss = 0.0028357473202049732 test lost = 0.0027606994844973087\n",
      "Step 5100 train loss = 0.0027278896886855364 test lost = 0.002653691451996565\n",
      "Step 5200 train loss = 0.0026267939247190952 test lost = 0.0025534701999276876\n",
      "Step 5300 train loss = 0.002532079117372632 test lost = 0.0024596485309302807\n",
      "Step 5400 train loss = 0.0024433222133666277 test lost = 0.002371804788708687\n",
      "Step 5500 train loss = 0.0023601509165018797 test lost = 0.002289558295160532\n",
      "Step 5600 train loss = 0.002282219473272562 test lost = 0.0022125616669654846\n",
      "Step 5700 train loss = 0.0022091709543019533 test lost = 0.0021404577419161797\n",
      "Step 5800 train loss = 0.0021407578606158495 test lost = 0.0020729913376271725\n",
      "Step 5900 train loss = 0.0020766162779182196 test lost = 0.0020097994711250067\n",
      "Step 6000 train loss = 0.0020165422465652227 test lost = 0.0019506748067215085\n",
      "Step 6100 train loss = 0.001960239140316844 test lost = 0.0018953190883621573\n",
      "Step 6200 train loss = 0.0019074708689004183 test lost = 0.0018434933153912425\n",
      "Step 6300 train loss = 0.001858028583228588 test lost = 0.0017949888715520501\n",
      "Step 6400 train loss = 0.0018117042491212487 test lost = 0.0017495960928499699\n",
      "Step 6500 train loss = 0.0017682971665635705 test lost = 0.0017071139300242066\n",
      "Step 6600 train loss = 0.0017276129219681025 test lost = 0.0016673445934429765\n",
      "Step 6700 train loss = 0.0016895036678761244 test lost = 0.0016301375580951571\n",
      "Step 6800 train loss = 0.0016537817427888513 test lost = 0.0015953091206029058\n",
      "Step 6900 train loss = 0.001620318740606308 test lost = 0.0015627277316525578\n",
      "Step 7000 train loss = 0.0015889465576037765 test lost = 0.0015322238905355334\n",
      "Step 7100 train loss = 0.0015595615841448307 test lost = 0.0015036948025226593\n",
      "Step 7200 train loss = 0.0015320280799642205 test lost = 0.0014770018169656396\n",
      "Step 7300 train loss = 0.0015062203165143728 test lost = 0.0014520225813612342\n",
      "Step 7400 train loss = 0.0014820342184975743 test lost = 0.0014286494115367532\n",
      "Step 7500 train loss = 0.0014593712985515594 test lost = 0.001406785799190402\n",
      "Step 7600 train loss = 0.001438140170648694 test lost = 0.00138633802998811\n",
      "Step 7700 train loss = 0.0014182470040395856 test lost = 0.0013672140194103122\n",
      "Step 7800 train loss = 0.0013996078632771969 test lost = 0.0013493269216269255\n",
      "Step 7900 train loss = 0.001382137299515307 test lost = 0.0013325951294973493\n",
      "Step 8000 train loss = 0.00136575719807297 test lost = 0.0013169387821108103\n",
      "Step 8100 train loss = 0.0013504103990271688 test lost = 0.0013022975763306022\n",
      "Step 8200 train loss = 0.0013360489392653108 test lost = 0.0012886275071650743\n",
      "Step 8300 train loss = 0.0013225676957517862 test lost = 0.0012758240336552262\n",
      "Step 8400 train loss = 0.0013099575880914927 test lost = 0.001263872836716473\n",
      "Step 8500 train loss = 0.001298119081184268 test lost = 0.0012526826467365026\n",
      "Step 8600 train loss = 0.0012870486825704575 test lost = 0.0012422404251992702\n",
      "Step 8700 train loss = 0.0012766544241458178 test lost = 0.0012324622366577387\n",
      "Step 8800 train loss = 0.0012669306015595794 test lost = 0.0012233384186401963\n",
      "Step 8900 train loss = 0.0012578143505379558 test lost = 0.0012148075038567185\n",
      "Step 9000 train loss = 0.001249263295903802 test lost = 0.0012068274663761258\n",
      "Step 9100 train loss = 0.0012412593932822347 test lost = 0.0011993827065452933\n",
      "Step 9200 train loss = 0.0012337592197582126 test lost = 0.0011924257269129157\n",
      "Step 9300 train loss = 0.0012267334386706352 test lost = 0.0011859276564791799\n",
      "Step 9400 train loss = 0.00122014619410038 test lost = 0.0011798548512160778\n",
      "Step 9500 train loss = 0.0012139729224145412 test lost = 0.0011741836788132787\n",
      "Step 9600 train loss = 0.00120818754658103 test lost = 0.0011688872473314404\n",
      "Step 9700 train loss = 0.0012027680641040206 test lost = 0.0011639428557828069\n",
      "Step 9800 train loss = 0.0011976887471973896 test lost = 0.0011593278031796217\n",
      "Step 9900 train loss = 0.0011929302709177136 test lost = 0.0011550197377800941\n"
     ]
    }
   ],
   "source": [
    "# Training model\n",
    "for step in range(num_steps):\n",
    "    optimizer.apply_gradients(grad(linear_regression, np.float32(X_train), np.float32(y_train)))\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        train_loss = loss_function(linear_regression,np.float32(X_train), np.float32(y_train))\n",
    "        test_loss = loss_function(linear_regression,np.float32(X_test), np.float32(y_test))\n",
    "        print(\"Step {} train loss = {} test lost = {}\".format(step,train_loss,test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.9429798, 3.904418 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.077955596"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = linear_regression(np.float32(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=221822, shape=(2000, 1), dtype=float32, numpy=\n",
       "array([[4.163293 ],\n",
       "       [2.6663632],\n",
       "       [5.3036027],\n",
       "       ...,\n",
       "       [2.3200119],\n",
       "       [3.9852767],\n",
       "       [2.8799388]], dtype=float32)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.17439516],\n",
       "       [2.63843097],\n",
       "       [5.33083517],\n",
       "       ...,\n",
       "       [2.27929094],\n",
       "       [3.9907316 ],\n",
       "       [2.86214506]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x252a02f0358>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEBxJREFUeJzt3X+M5PVdx/HXazloXUoLeGtFjrstpmmiRuAyIVSUVGjwwAaqaQzNtGJrsmlsDSQaxVxSmyb8UY2NP2JqVlqtuloiLZaQtnKxkMY/ODt7PSj0sFzJLj25cltbgbqJCPf2j+93vWGY2fnOfuc73/nM9/lINjPznc/svPO92dd9vp/5fD9fR4QAAOmYq7sAAMBoCG4ASAzBDQCJIbgBIDEENwAkhuAGgMQQ3ACQGIIbABJDcANAYnZV8Ut3794di4uLVfxqAJhJq6ur342IhSJtKwnuxcVFdTqdKn41AMwk2+tF2zJUAgCJIbgBIDEENwAkhuAGgMQQ3ACQGIIbmAIrK9LiojQ3l92urNRdEaZZJdMBARS3siItLUmbm9nj9fXssSS12/XVhelFjxuo2cGDZ0J7y+Zmth3oh+AGavb006NtBwhuoGZ79462HSC4gZrdeac0P//KbfPz2XagH4IbqFm7LS0vS/v2SXZ2u7zMF5MYjFklwBRotwlqFEePGwASQ3ADQGIIbgBITKHgtn2+7XtsP2H7mO23Vl0YAKC/ol9O/omkL0XEu2yfI2l+2AsAANUYGty2Xy/pGkm/JkkR8aKkF6stCwAwSJGhkkslbUj6K9tfs32X7XN7G9lest2x3dnY2Bh7oQCATJHg3iVpv6RPRMQVkv5b0h29jSJiOSJaEdFaWCh0oWIAwA4UCe4Tkk5ExOH88T3KghwAUIOhwR0R35H0bdtvyTddJ+kblVYFABio6KyS35S0ks8oeUrS+6orCQCwnULzuCPiaD5+/dMR8c6I+H7VhQHApKR26TgWmQLQaCleOo5T3gE0WoqXjiO4ATRaipeOI7gBNFqKl44juAE0WoqXjiO4ATRaipeOY1YJgMZL7dJx9LgBIDEENwAkhuAGgMQQ3ACQGIJ7TFJb6wBAuphVMgYprnUAIF30uMcgxbUOAKSL4B6DFNc6AJAugnsMUlzrAEC6CO4xSHGtAwDpIrjHIMW1DgCki+DOlZ3O125La2vS6dPZLaENoCpMBxTT+QCkhR63mM4HIC0Et5jOByAtBLeYzgcgLQS3mM4HIC0Et5jOByAtzCrJpXbpIgDNRY8bABJDcANAYghuAEgMwQ0AiSG4AXDpvcQUmlVie03SC5JelvRSRLSqLArA5LBWT3pG6XH/fERcTmgDs4W1etLDUAnQcKzVk56iwR2SHrC9anupyoIATBZr9aSnaHBfHRH7Jd0g6YO2r+ltYHvJdsd2Z2NjY6xFAqgOa/Wkp1BwR8Qz+e0pSfdKurJPm+WIaEVEa2FhYbxVAqgMa/WkZ+isEtvnSpqLiBfy+9dL+mjllQGYGNbqSUuR6YBvlHSv7a32fx8RX6q0KgDAQEODOyKeknTZBGoBABTAdEAASAzBDQCJIbgBIDEENwAkhuAGgMQQ3ACQGIIbABJDcANAYghuAEgMwQ0AiSG4ASAxBDeA2nGx4tEUulgwAFSFixWPjh43gFpxseLREdwAasXFikdHcAOoFRcrHh3BDaBWXKx4dAQ3gFpxseLRMasEQO24WPFo6HEDQGIIbgBIDMENAIkhuAEgMQQ3ACSG4AaAxExNcLM6GAAUMxXzuFkdDACKm4oeN6uDAUBxUxHcrA4GAMVNRXCzOhgAFDcVwc3qYABQXOHgtn2W7a/Zvn/cRbA6GAAUN8qsktskHZP0+ioKYXUwACimUI/b9h5JvyjprmrLAQAMU3So5I8l/Y6k0xXWAgAoYGhw236HpFMRsTqk3ZLtju3OxsbG2AoEALxSkR731ZJusr0m6TOSrrX9d72NImI5IloR0VpYWBhzmQCALUODOyJ+LyL2RMSipFskfTki3lN5ZQCAvqZiHjdQNxY5Q0pGWmQqIh6S9FAllQA1YZEzpIYeNxqPRc6QGoIbjcciZ0gNwY3GY5EzpIbgRuOxyBlSQ3Cj8VjkDKkhuDETyk7na7eltTXp9OnsltDGNJuKa04CZTCdD01DjxvJYzofmobgRvKYzoemIbinBKdc7xzT+dA0BPcU2BqjXV+XIs6M0RLexTCdD01DcE8BxmjLYTofmsYRMfZf2mq1otPpjP33zqq5uayn3cvOpqcBmH22VyOiVaQtPe4pwBgtgFEQ3FOAMVoAoyC4pwBjtABGwZmTU6LdJqgBFEOPGwASQ3ADQGIIbgBIDME9IzhlHmgOvpycASxrCjQLPe4ZwCnzQLMQ3DOAZU2BZiG4ZwCnzAPNQnDPAE6ZB5qF4J4BnDIPNAuzSmYEp8wDzUGPGwASQ3ADQGIIbmAGcOZsswwd47b9WklfkfSavP09EfH7VRcGoBjOnG2eIj3u/5F0bURcJulySQdsX1VtWQCK4szZ5hna447sasI/yB+enf+M/wrDAHaEM2ebp9AYt+2zbB+VdErSoYg4XG1ZAIrizNnmKRTcEfFyRFwuaY+kK23/VG8b20u2O7Y7Gxsb464TwACcOds8I80qiYj/kvSQpAN9nluOiFZEtBYWFsZUHoBhOHO2ebNqhga37QXb5+f3f0jS2yU9UXVhQErqDo52W1pbk06fzm6bFtpLS9lsmogzs2pmObyL9LgvkvSg7UclfVXZGPf91ZaF1NQdXHVqYnBMkybOqnE2aWS8Wq1WdDqdsf9eTKfeecRSNsbalMP1xcUsrHvt25f1flGtubnsP8xednYEkgrbqxHRKtKWMydRWhN7PN2YjlevJs6qIbhRWtODq4nBMU2aOKuG4EZpTQ+uJgbHNGnirBqCG6U1PbiaGBzTpmmzariQAkrb+iM5eDAbHtm7NwvtWf/j6caFLDBJBDfGguACJoehEgBIzMwEd5NPAAHQLDMxVMJC8gCaZCZ63E0/AWQcOGIB0jETPe6mnwBSFkcsQFpmosfd9BNAyuKIBUjLTAR3008AKYsjFiAtMxHcnLlWDkcsQFpmIril5p3yOk4csQBpmZngxs5xxAKkZSZmlaA8TlkH0kGPGwASQ3ADQGIIbgBIDMENAIkhuAEgMQQ3ACSG4AaAkia9uibzuAGghDpW16THDQAl1LG6JsGNqcCFHJCqOlbXJLhRu61DzfV1KeLMoSbhjRTUsbomwY3acSEHpKyO1TUJbtSOCzkgZXWsrsmsEtRu795seKTfdiAFk15dkx43aseFHIDRDA1u25fYftD2MduP275tEoWhObiQAzCaIkMlL0n6rYg4Yvs8Sau2D0XENyquDQ3ChRyA4ob2uCPiZEQcye+/IOmYpIurLgwA0N9IY9y2FyVdIelwn+eWbHdsdzY2NsZTHQDgVQoHt+3XSfqspNsj4vne5yNiOSJaEdFaWFgYZ40AgC6Fgtv22cpCeyUiPldtSQCA7RSZVWJJn5R0LCI+Xn1JAIDtFOlxXy3pvZKutX00/7mx4roAAAMMnQ4YEf8qyROoBQBQAGdOAkBiCG4ASAzBDQCJIbgBIDEENwAkhuAGgMQQ3ACQGIIbABJDcANAYghuAEgMwQ0AiSG4ASAxBDcAJIbgBoDEENwAkBiCGwASQ3ADQGIIbgClraxIi4vS3Fx2u7JSd0WzbeilywBgOysr0tKStLmZPV5fzx5LUrtdX12zjB43gFIOHjwT2ls2N7PtqAbBDaCUp58ebTvKI7gBlLJ372jbUR7BDaCUO++U5udfuW1+PtuOahDcAEppt6XlZWnfPsnObpeX+WKySswqAVBau01QTxI9bgBIDMENAIkhuAEgMQQ3ACSG4AaAxDgixv9L7Q1J6zt8+W5J3x1jOeNGfeVQXznUV84017cvIhaKNKwkuMuw3YmIVt11DEJ95VBfOdRXzrTXVxRDJQCQGIIbABIzjcG9XHcBQ1BfOdRXDvWVM+31FTJ1Y9wAgO1NY48bALCN2oLb9gHb/277uO07+jz/Gtt3588ftr04wdousf2g7WO2H7d9W582b7P9nO2j+c+HJ1Vf/v5rtr+ev3enz/O2/af5/nvU9v4J1vaWrv1y1Pbztm/vaTPR/Wf7U7ZP2X6sa9uFtg/ZfjK/vWDAa2/N2zxp+9YJ1veHtp/I//3utX3+gNdu+1mosL6P2P6Prn/DGwe8dtu/9Qrru7urtjXbRwe8tvL9N3YRMfEfSWdJ+pakSyWdI+kRST/R0+Y3JP1Ffv8WSXdPsL6LJO3P758n6Zt96nubpPvr2H/5+69J2r3N8zdK+qIkS7pK0uEa/62/o2yOam37T9I1kvZLeqxr2x9IuiO/f4ekj/V53YWSnspvL8jvXzCh+q6XtCu//7F+9RX5LFRY30ck/XaBf/9t/9arqq/n+T+S9OG69t+4f+rqcV8p6XhEPBURL0r6jKSbe9rcLOnT+f17JF1n25MoLiJORsSR/P4Lko5JungS7z1GN0v6m8g8LOl82xfVUMd1kr4VETs9IWssIuIrkr7Xs7n7M/ZpSe/s89JfkHQoIr4XEd+XdEjSgUnUFxEPRMRL+cOHJe0Z9/sWNWD/FVHkb7207erLc+NXJP3DuN+3LnUF98WSvt31+IReHYz/3yb/8D4n6YcnUl2XfIjmCkmH+zz9VtuP2P6i7Z+caGFSSHrA9qrtpT7PF9nHk3CLBv/B1Ln/JOmNEXFSyv6zlvQjfdpMy358v7IjqH6GfRaq9KF8KOdTA4aapmH//ZykZyPiyQHP17n/dqSu4O7Xc+6d3lKkTaVsv07SZyXdHhHP9zx9RNnh/2WS/kzSP02yNklXR8R+STdI+qDta3qen4b9d46kmyT9Y5+n695/RU3Dfjwo6SVJKwOaDPssVOUTkn5c0uWSTiobjuhV+/6T9G5t39uua//tWF3BfULSJV2P90h6ZlAb27skvUE7O1TbEdtnKwvtlYj4XO/zEfF8RPwgv/8FSWfb3j2p+iLimfz2lKR7lR2Sdiuyj6t2g6QjEfFs7xN177/cs1vDR/ntqT5tat2P+Zeh75DUjnxAtleBz0IlIuLZiHg5Ik5L+ssB71v3/tsl6Zcl3T2oTV37r4y6gvurkt5s+015r+wWSff1tLlP0tY3+O+S9OVBH9xxy8fEPinpWER8fECbH90ac7d9pbJ9+Z8Tqu9c2+dt3Vf2JdZjPc3uk/Sr+eySqyQ9tzUsMEEDezp17r8u3Z+xWyV9vk+bf5Z0ve0L8qGA6/NtlbN9QNLvSropIjYHtCnyWaiqvu7vTH5pwPsW+Vuv0tslPRERJ/o9Wef+K6Wub0WVzXr4prJvnA/m2z6q7EMqSa9Vdoh9XNK/Sbp0grX9rLLDuUclHc1/bpT0AUkfyNt8SNLjyr4lf1jSz0ywvkvz930kr2Fr/3XXZ0l/nu/fr0tqTfjfd15ZEL+ha1tt+0/ZfyAnJf2vsl7gryv7zuRfJD2Z316Yt21Juqvrte/PP4fHJb1vgvUdVzY+vPUZ3Jpl9WOSvrDdZ2FC9f1t/tl6VFkYX9RbX/74VX/rk6gv3/7XW5+5rrYT33/j/uHMSQBIDGdOAkBiCG4ASAzBDQCJIbgBIDEENwAkhuAGgMQQ3ACQGIIbABLzf11qKDFXhRQFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(y_test[:20])), y_test[:20], 'bo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x252a0604470>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(y_pred.numpy()[:20])), y_pred.numpy()[:20], 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
